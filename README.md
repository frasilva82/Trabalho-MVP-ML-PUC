# Trabalho-MVP-ML-PUC
MVP de Machine Learning ‚Äì Previs√£o de NPS em C+6
Contexto

Este projeto faz parte da disciplina de Machine Learning da PUC, mas foi inspirado em um desafio que vivencio na pr√°tica. Trabalho como Coordenador de Experi√™ncia do Cliente (CX) e CRM em uma construtora, e um dos maiores pontos de aten√ß√£o na √°rea √© identificar clientes que podem ficar insatisfeitos antes da pesquisa final de NPS, que acontece seis meses ap√≥s a entrega das chaves.

A ideia aqui foi trazer esse problema real para dentro do curso e construir um MVP preditivo, testando diferentes modelos de aprendizado de m√°quina para verificar se conseguimos antecipar a percep√ß√£o do cliente e atuar de forma preventiva.

Objetivo

O objetivo √© prever se um cliente ser√°:

Detrator (nota 0‚Äì6),

Neutro (nota 7‚Äì8) ou

Promotor (nota 9‚Äì10)

na pesquisa de NPS C+6.

As vari√°veis consideradas incluem:

Nota dada no NPS da vistoria

Perfil socioecon√¥mico: renda, idade, filhos, estado civil, escolaridade

Dados operacionais: meses para entrega, status e acionamentos da assist√™ncia t√©cnica

Regi√£o e safra de obras

Etapas do Trabalho

Carga e prepara√ß√£o dos dados

Leitura da base em CSV

Cria√ß√£o da vari√°vel alvo nps_6m_target

Ajuste de tipos e tratamento de valores ausentes

Explora√ß√£o e pr√©-processamento

An√°lise da distribui√ß√£o das classes (Detratores 48%, Promotores 32%, Neutros 20%)

Tratamento de missing values (mediana/moda)

Padroniza√ß√£o e codifica√ß√£o via pipeline

Divis√£o treino/teste estratificada

Modelagem

Baseline: Dummy Classifier

Modelos lineares e probabil√≠sticos (Regress√£o Log√≠stica, Naive Bayes)

√Årvores e ensembles (Decision Tree, Random Forest, Bagging, Extra Trees, Voting)

Boosting (AdaBoost, Gradient Boosting, XGBoost)

Avalia√ß√£o

Valida√ß√£o cruzada estratificada (k=5)

M√©tricas: accuracy, f1-macro, precision, recall

Compara√ß√£o e ranking de modelos

Otimiza√ß√£o de hiperpar√¢metros

GridSearchCV no AdaBoost

Melhor configura√ß√£o: n_estimators=100, learning_rate=0.5, max_depth=3

f1-macro em CV: ~0,49

Aplica√ß√£o pr√°tica

Simula√ß√£o de clientes fict√≠cios

Previs√£o da classe (Detrator, Neutro ou Promotor)

Discuss√£o sobre uso real no neg√≥cio

Resultados
Modelo	Accuracy	f1-macro	Observa√ß√µes
Dummy (Baseline)	0,48	0,21	Sempre prev√™ Detrator
Logistic Regression	0,56	0,43	Melhor que baseline, mas fraco em Neutros
Random Forest	0,54	0,43	Est√°vel, mas sem destaque
Gradient Boosting	0,57	~0,45	Bom equil√≠brio
AdaBoost (default)	0,58	~0,46	Melhor desempenho geral
AdaBoost (tuning)	0,53	0,45	Refinou Detratores e Promotores, mas Neutros seguem cr√≠ticos

üìå Insight: os algoritmos de boosting foram os que mais se destacaram, mas a classe Neutro continua sendo dif√≠cil de prever devido ao desbalanceamento.

Pr√≥ximos Passos

Testar t√©cnicas de balanceamento (SMOTE, class_weight)

Explorar variantes modernas como LightGBM e CatBoost

Analisar import√¢ncia das vari√°veis para entender os fatores que mais pesam no NPS

Integrar o modelo em um painel de CX para apoiar a√ß√µes preventivas

Como Executar
Clonar o reposit√≥rio
git clone https://github.com/frasilva82/Trabalho-MVP-ML-PUC.git
cd Trabalho-MVP-ML-PUC

Rodar no Google Colab

Abra o notebook diretamente pelo link:
üëâ Abrir no Colab

Rodar localmente

Instale as depend√™ncias principais:

pip install pandas numpy scikit-learn xgboost matplotlib


Depois, abra o notebook MVP_NPS.ipynb no Jupyter Notebook ou VSCode.

Autor

Francisco Almeida da Silva
Coordenador de Experi√™ncia do Cliente (CX) e CRM ‚Äì Construtora Tenda

Projeto desenvolvido no curso de Machine Learning da PUC, inspirado em desafios reais de gest√£o de NPS.
